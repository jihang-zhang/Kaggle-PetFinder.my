{"cells":[{"metadata":{"trusted":true,"_uuid":"787f485613f3c19812d267799f50e91f530f0976","scrolled":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install ../input/pretrainedmodelspython/pretrainedmodels-0.7.4-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"691a7e58ef98284ce6bfb703197b1d512d4523a7","trusted":true},"cell_type":"code","source":"import gc\nimport glob\nimport os\nimport sys\nimport json\nimport random\nimport time\nimport re\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import kurtosis, iqr, skew\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nimport category_encoders as ce\n\nimport torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch.optim import Optimizer\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\n\nimport gensim\nfrom gensim.models import FastText\nfrom keras.preprocessing.sequence import pad_sequences\nimport spacy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c2184845b750333c1e29526ec6ec8126d8d42a0","trusted":true},"cell_type":"code","source":"def set_seed(seed=4334):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = False\n    \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED = 4334\nBATCH_SIZE = 512\nn_fold = 5\n\nset_seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e29f51058918017c57afb70f6cd4cd29ad9d53e","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Loading data ...\")\n\ntrain = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntest = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\nsample_submission = pd.read_csv('../input/petfinder-adoption-prediction/test/sample_submission.csv')\n\ntrain_size = train.shape[0]\ntest_size = test.shape[0]\n\nprint(train.shape)\nprint(test.shape)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a9198fe2ac4bbc947fbfbd5f60a5482c4d70d8b"},"cell_type":"markdown","source":"# Image feature extraction"},{"metadata":{"_uuid":"fa202a8fbd602f687a3ba406f8b23b79fb3cd694","trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport pretrainedmodels\nimport torchvision.transforms as transforms\n\nimport fastai\nfrom fastai.imports import *\nfrom fastai.vision import *\nfrom fastai.metrics import *\nfrom fastai.gen_doc.nbdoc import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"standardize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n\"\"\"\nDefine Dataset to load image\n\"\"\"\n\ndef resize_to_square(im):\n    old_size = im.shape[:2]\n    ratio = float(img_size)/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h//2, delta_h-(delta_h//2)\n    left, right = delta_w//2, delta_w-(delta_w//2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n    return new_im\n    \ndef load_image(img_dir):\n    image = cv2.imread(img_dir, 1)\n    image = resize_to_square(image)\n    image = standardize(transforms.functional.to_tensor(image)).cuda()\n    return image\n\ndef get_keys(img_dir):\n    pet_id, img_num = re.search('_images/' + '(.*).jpg', img_dir).group(1).split('-')\n    return pet_id, img_num","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Model (seResNeXt50)"},{"metadata":{"trusted":true},"cell_type":"code","source":"seresnext50 = pretrainedmodels.__dict__['se_resnext50_32x4d'](num_classes=1000, pretrained=None)\nseresnext50.load_state_dict(torch.load('../input/pretrainedmodelsweights/seresnext50.pth'))\nseresnext50 = seresnext50.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 224\nimg_batch_size = 48\nsoftmax = nn.Softmax(dim=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_dir = glob.glob(f'../input/petfinder-adoption-prediction/train_images/*.jpg')\nn_batches = len(train_img_dir) // img_batch_size + (len(train_img_dir) % img_batch_size != 0)\n\nseresnext50_predict_train = {}\nseresnext50.eval()\nfor b in tqdm(range(n_batches)):\n    start = b*img_batch_size\n    end = (b+1)*img_batch_size\n    batch_pets = train_img_dir[start:end]\n    batch_images = torch.zeros((len(batch_pets), 3, img_size, img_size)).cuda()\n    for i, img_dir in enumerate(batch_pets):\n        batch_images[i] = load_image(img_dir)\n    batch_hats = softmax(seresnext50(batch_images))\n    for i, img_dir in enumerate(batch_pets):\n        pet_id, img_num = get_keys(img_dir)\n        if pet_id not in seresnext50_predict_train:\n            seresnext50_predict_train[pet_id] = {}\n        seresnext50_predict_train[pet_id][int(img_num)] = batch_hats[i].argmax().detach().cpu().numpy() + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_dir = glob.glob(f'../input/petfinder-adoption-prediction/test_images/*.jpg')\nn_batches = len(test_img_dir) // img_batch_size + (len(test_img_dir) % img_batch_size != 0)\n\nseresnext50_predict_test = {}\nseresnext50.eval()\nfor b in tqdm(range(n_batches)):\n    start = b*img_batch_size\n    end = (b+1)*img_batch_size\n    batch_pets = test_img_dir[start:end]\n    batch_images = torch.zeros((len(batch_pets), 3, img_size, img_size)).cuda()\n    for i, img_dir in enumerate(batch_pets):\n        batch_images[i] = load_image(img_dir)\n    batch_hats = softmax(seresnext50(batch_images))\n    for i, img_dir in enumerate(batch_pets):\n        pet_id, img_num = get_keys(img_dir)\n        if pet_id not in seresnext50_predict_test:\n            seresnext50_predict_test[pet_id] = {}\n        seresnext50_predict_test[pet_id][int(img_num)] = batch_hats[i].argmax().detach().cpu().numpy() + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process image prediction features\n\nimg_seq_len = 12\npet_ids = train['PetID'].values\nseresnext50_pred_train = np.zeros((train_size, img_seq_len))\n\nfor i, pet_id in enumerate(tqdm(pet_ids)):\n    if pet_id in seresnext50_predict_train:\n        for j in seresnext50_predict_train[pet_id]:\n            if j <= img_seq_len:\n                seresnext50_pred_train[i, j-1] = seresnext50_predict_train[pet_id][j]\n            else:\n                pass\n    else:\n        pass\n\npet_ids = test['PetID'].values\nseresnext50_pred_test = np.zeros((test_size, img_seq_len))\n\nfor i, pet_id in enumerate(tqdm(pet_ids)):\n    if pet_id in seresnext50_predict_test:\n        for j in seresnext50_predict_test[pet_id]:\n            if j <= img_seq_len:\n                seresnext50_pred_test[i, j-1] = seresnext50_predict_test[pet_id][j]\n            else:\n                pass\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del seresnext50, seresnext50_predict_train, seresnext50_predict_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cuteness Model (DenseNet201)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fastai2pytorch(fastai_model, n_class):\n    body = create_body(fastai_model, False, None)\n    nf = callbacks.hooks.num_features_model(body) * 2\n    head = create_head(nf, n_class, None, ps=0.5, bn_final=False)\n    return nn.Sequential(body, head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cute_model = fastai2pytorch(models.densenet201, 2)\ncute_model.load_state_dict(torch.load('../input/cat-and-dog-pretrained-weights/densenet201_cuteness.pth')['model'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CuteBottom(nn.Module):\n    def __init__(self, cute_model):\n        super(CuteBottom, self).__init__()\n        \n        children = list(cute_model.children())\n        self.backbone = children[0]\n        self.features = nn.Sequential(*list(children[1].children())[:-4])\n        self.head = nn.Sequential(*list(children[1].children())[-4:])\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.features(x)\n        return x\n    \n    def predict_on_hidden(self, x):\n        return self.softmax(self.head(x))\n    \ncute_bottom = CuteBottom(cute_model)\ncute_bottom = cute_bottom.cuda()\n\ndel cute_model\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dd736374c0db9143898dbe39d550f27ac77989c"},"cell_type":"code","source":"img_size = 224\nimg_batch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5f7c69167320c527bb441a0353b1219763a570c","trusted":true},"cell_type":"code","source":"train_img_dir = glob.glob(f'../input/petfinder-adoption-prediction/train_images/*.jpg')\nn_batches = len(train_img_dir) // img_batch_size + (len(train_img_dir) % img_batch_size != 0)\n\nimg_features_train = {}\nimg_cute_train = {}\ncute_bottom.eval()\nfor b in tqdm(range(n_batches)):\n    start = b*img_batch_size\n    end = (b+1)*img_batch_size\n    batch_pets = train_img_dir[start:end]\n    batch_images = torch.zeros((len(batch_pets), 3, img_size, img_size)).cuda()\n    for i, img_dir in enumerate(batch_pets):\n        batch_images[i] = load_image(img_dir)\n    batch_preds = cute_bottom(batch_images)\n    batch_preds_arr = batch_preds.detach().cpu().numpy()\n    batch_hats = cute_bottom.predict_on_hidden(batch_preds).detach()\n    for i, img_dir in enumerate(batch_pets):\n        pet_id, img_num = get_keys(img_dir)\n        if pet_id not in img_features_train:\n            img_features_train[pet_id] = {}\n            img_cute_train[pet_id] = {}\n        img_features_train[pet_id][int(img_num)] = batch_preds_arr[i]\n        img_cute_train[pet_id][int(img_num)] = batch_hats[i].argmax().cpu().numpy() + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33b2f10e2a96c58bf6ec29fc3e82ef658b30dedf","trusted":true},"cell_type":"code","source":"test_img_dir = glob.glob(f'../input/petfinder-adoption-prediction/test_images/*.jpg')\nn_batches = len(test_img_dir) // img_batch_size + (len(test_img_dir) % img_batch_size != 0)\n\nimg_features_test = {}\nimg_cute_test = {}\ncute_bottom.eval()\nfor b in tqdm(range(n_batches)):\n    start = b*img_batch_size\n    end = (b+1)*img_batch_size\n    batch_pets = test_img_dir[start:end]\n    batch_images = torch.zeros((len(batch_pets), 3, img_size, img_size)).cuda()\n    for i, img_dir in enumerate(batch_pets):\n        batch_images[i] = load_image(img_dir)\n    batch_preds = cute_bottom(batch_images)\n    batch_preds_arr = batch_preds.detach().cpu().numpy()\n    batch_hats = cute_bottom.predict_on_hidden(batch_preds).detach()\n    for i, img_dir in enumerate(batch_pets):\n        pet_id, img_num = get_keys(img_dir)\n        if pet_id not in img_features_test:\n            img_features_test[pet_id] = {}\n            img_cute_test[pet_id] = {}\n        img_features_test[pet_id][int(img_num)] = batch_preds_arr[i]\n        img_cute_test[pet_id][int(img_num)] = batch_hats[i].argmax().detach().cpu().numpy() + 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"812e626e9371c27601db01e468f5f78405e20ca0","trusted":true},"cell_type":"code","source":"# Process image features\n\nimg_feat_dim = 512\nimg_seq_len = 12\npet_ids = train['PetID'].values\nimg_seq_train = np.zeros((train_size, img_seq_len, img_feat_dim))\n\nfor i, pet_id in enumerate(tqdm(pet_ids)):\n    if pet_id in img_features_train:\n        for j in img_features_train[pet_id]:\n            if j <= img_seq_len:\n                img_seq_train[i, j-1, :] = img_features_train[pet_id][j]\n            else:\n                pass\n    else:\n        pass\n    \n\npet_ids = test['PetID'].values\nimg_seq_test = np.zeros((test_size, img_seq_len, img_feat_dim))\n\nfor i, pet_id in enumerate(tqdm(pet_ids)):\n    if pet_id in img_features_test:\n        for j in img_features_test[pet_id]:\n            if j <= img_seq_len:\n                img_seq_test[i, j-1, :] = img_features_test[pet_id][j]\n            else:\n                pass\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47324c5f13a440e173d522045ec39e1bcae25f71"},"cell_type":"code","source":"# Process image prediction features\n\nimg_seq_len = 12\npet_ids = train['PetID'].values\ncuteness_train = np.zeros((train_size, img_seq_len))\n\nfor i, pet_id in enumerate(tqdm(pet_ids)):\n    if pet_id in img_cute_train:\n        for j in img_cute_train[pet_id]:\n            if j <= img_seq_len:\n                cuteness_train[i, j-1] = img_cute_train[pet_id][j]\n            else:\n                pass\n    else:\n        pass\n\npet_ids = test['PetID'].values\ncuteness_test = np.zeros((test_size, img_seq_len))\n\nfor i, pet_id in enumerate(tqdm(pet_ids)):\n    if pet_id in img_cute_test:\n        for j in img_cute_test[pet_id]:\n            if j <= img_seq_len:\n                cuteness_test[i, j-1] = img_cute_test[pet_id][j]\n            else:\n                pass\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48813c05e49b97ea81337e028f36182cdfd3a9eb"},"cell_type":"code","source":"del cute_bottom, img_features_train, img_features_test, img_cute_train, img_cute_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07011276539c055b43ee92c959afd3e45bca5ce8"},"cell_type":"markdown","source":"# Description processing"},{"metadata":{"_uuid":"44ed086cd52bf30d65dc6f1775709da27d45861a","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Loading text data ...\")\ntrain_text = train['Description'].fillna(' ')\ntest_text = test['Description'].fillna(' ')\ntext_list = pd.concat([train_text, test_text])\n\nplt.hist([len(sentence.split()) for sentence in text_list], bins=50)\nplt.axvline(x=200, color='r')\nplt.show()\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c0117f88b0d507766786b211dceb80beb2b7574","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Spacy NLP ...\")\nnlp = spacy.load('en_core_web_lg', disable=['parser','ner','tagger'])\nnlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\nword_dict = {}\nword_index = 1\nlemma_dict = {}\ndocs = nlp.pipe(text_list, n_threads = 6)\nword_sequences = []\nsentences = []\nfor doc in tqdm(docs):\n    word_seq = []\n    sentence_seq = []\n    for token in doc:\n        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\n            word_dict[token.text] = word_index\n            word_index += 1\n            lemma_dict[token.text] = token.lemma_\n        if token.pos_ is not \"PUNCT\":\n            word_seq.append(word_dict[token.text])\n            sentence_seq.append(token.text)\n    word_sequences.append(word_seq)\n    sentences.append(sentence_seq)\ndel docs\ngc.collect()\ntrain_word_sequences = word_sequences[:train_size]\ntest_word_sequences = word_sequences[train_size:]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82361d7ec69b5b1c8e37216dc9bd8df88e9500c7","trusted":true},"cell_type":"code","source":"max_length = 200\nembed_size = 300\n\ntrain_word_sequences = pad_sequences(train_word_sequences, maxlen=max_length, padding='pre')\ntest_word_sequences = pad_sequences(test_word_sequences, maxlen=max_length, padding='pre')\nprint(train_word_sequences[:1])\nprint(test_word_sequences[:1])\npred_prob = np.zeros((len(test_word_sequences),), dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0023cb18fafa7aea00258451760ed25ed7a47be2","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Training fastText ...\")\n\nft_model = FastText(size=embed_size, min_count=1)\nft_model.build_vocab(sentences=sentences)\nft_model.train(sentences=sentences, total_examples=len(sentences), epochs=10)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0070f0b32e1c0bb0c466416c87afea6fc113213a","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Loading embedding matrix ...\")\n\ndef load_fasttext(word_dict):\n    nb_words = len(word_dict) + 1\n    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n    \n    for word in tqdm(word_dict):\n        embedding_matrix[word_dict[word]] = ft_model.wv[word]\n    return embedding_matrix, nb_words\n\nembedding_matrix, nb_words = load_fasttext(word_dict)\nn_words = len(embedding_matrix)\nprint(embedding_matrix.shape)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f48355c0f51945a86f8d1eaa58858cc65df66b6"},"cell_type":"code","source":"del ft_model\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ac3489f72c109515e181dd35aca909c2b8eb7c9"},"cell_type":"markdown","source":"# Name text processing"},{"metadata":{"_uuid":"c72c395974f9ff036af54f4bd5f1ab3e4aba39a0","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Loading name data ...\")\ntrain_name = train['Name'].fillna(' ')\ntest_name = test['Name'].fillna(' ')\nname_list = pd.concat([train_name, test_name])\n\nplt.hist([len(name) for name in name_list], bins=40)\nplt.axvline(x=20, color='r')\nplt.show()\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cda5062f7b40a95d9a385ac00f00194482c04437","trusted":true},"cell_type":"code","source":"start_time = time.time()\nprint(\"Generating name sequences ...\")\n\nall_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 -,;.!?:’/\\|_@#$%ˆ&*˜‘+=()[]{}'\nn_letters = len(all_letters)\n\nletter_dict = {all_letters[i]: i for i in range(n_letters)}\nletter_sequences = []\nfor name in name_list.values:\n    letter_seq = []\n    for letter in name:\n        try:\n            letter_seq.append(letter_dict[letter])\n        except KeyError:\n            letter_seq.append(len(letter_dict))\n    letter_sequences.append(letter_seq)\n\ntrain_name_sequences = letter_sequences[:train_size]\ntest_name_sequences = letter_sequences[train_size:]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62af40ed7143f8420cb87ca06bf3387e19fc06ea","trusted":true},"cell_type":"code","source":"maxlen_name = 20\nembed_size_name = n_letters + 1\n\ntrain_name_sequences = pad_sequences(train_name_sequences, maxlen=maxlen_name, padding='pre')\ntest_name_sequences = pad_sequences(test_name_sequences, maxlen=maxlen_name, padding='pre')\nprint(train_name_sequences[:1])\nprint(test_name_sequences[:1])\n\nname_embed_mat = np.eye(94, 93, k=-1, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"928882564536feea52fc1036cc8a88fff39ea18a"},"cell_type":"markdown","source":"# Main table feature engineering"},{"metadata":{"trusted":true,"_uuid":"864d22e8783bc53302fcedfca9ad5667c8efd6d8"},"cell_type":"code","source":"train_proc = train.copy()\ntest_proc = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8eb679e4a91d9f6f6c02dd0dc78d0f5a1d46c61e","scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)\nX_temp = df.copy()\n\ny_temp = X_temp['AdoptionSpeed']\nX_temp = X_temp.drop(['AdoptionSpeed'], axis=1)\n\nprint('NaN structure:\\n{}'.format(np.sum(pd.isnull(df))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72e96e7ee4447832eb6bb7e5b23d802cdf8517bb"},"cell_type":"markdown","source":"## Additional State Data"},{"metadata":{"trusted":true,"_uuid":"d6d27166474f0c335dd5a80b9a3556bd1f1df7c4"},"cell_type":"code","source":"state_info = pd.read_csv('../input/stateinfo/State info.csv')\n\nX_temp = X_temp.merge(\n    state_info, how='left', on='State',\n    suffixes=('', '_state')\n)\n\nX_temp['population_density'] = X_temp['Population'] / X_temp['Total Area']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"480baec688f85ceb91f9e1db31548d7edbf2707b"},"cell_type":"markdown","source":"## is_mixed_breed, n_color, contains_chinese"},{"metadata":{"_uuid":"4c13985b4d4be7bf5fc31368db3165a5097e3413","trusted":true},"cell_type":"code","source":"X_temp['is_mixed_breed'] = X_temp.apply(lambda x: 0 if x.Breed2==0 and x.Breed1!=307 else 1, axis=1)\nX_temp['n_color'] = X_temp.apply(lambda x:  3-sum([y==0 for y in [x.Color1, x.Color2, x.Color3]]), axis=1)\n\n# contains_chinese\ndef isChinese(s):\n    if type(s) != str:\n        return 2\n    if len(re.findall(u'[\\u4e00-\\u9fff]', s)) > 0:\n        return 1\n    else:\n        return 0\nX_temp['contains_chinese'] = X_temp['Description'].map(isChinese)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"243dd0ef96ced988ff96802aaf73b690b3a8c4e9"},"cell_type":"markdown","source":"## is_nameless"},{"metadata":{"_uuid":"4f6e736f0f6b2c7529b724e77197c111facae947","trusted":true},"cell_type":"code","source":"names = X_temp.Name.unique()\nno_names = []\nfor name in names:\n    if type(name) is float:\n        continue\n    if 'name' in name.lower() or 'kitt' in name.lower() or 'pupp' in name.lower() or 'cats' in name.lower() or 'dogs' in name.lower():\n        no_names += [name]\n\nX_temp['is_nameless'] = (pd.isnull(X_temp['Name'])).astype(np.int64)\n\nfor index in range(len(X_temp['Name'])):\n    if type(X_temp['Name'].iloc[index]) == float:\n        continue\n    if X_temp['Name'].iloc[index] in no_names:\n        X_temp.loc[index, 'is_nameless'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3edc3db6b677f2a863639ba42b1d783ae3ee3eb9"},"cell_type":"markdown","source":"# Final Processing"},{"metadata":{"_uuid":"6f94830650bbacfda455309930fd61c1cbfdbe74","scrolled":true,"trusted":true},"cell_type":"code","source":"print('NaN structure:\\n{}'.format(np.sum(pd.isnull(X_temp))))\nprint('-'*99)\n\ncolumn_types = X_temp.dtypes\n\nprint('\\tinteger columns:\\n{}'.format(column_types[column_types == np.int64]))\nprint('\\n\\tfloat columns:\\n{}'.format(column_types[column_types == 'float']))\nprint('\\n\\tto encode categorical columns:\\n{}'.format(column_types[column_types == 'object']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecb6db428c4ab5cdbd8a816c53e4d8a8cc52234e"},"cell_type":"markdown","source":"## Label encoding for categorical features"},{"metadata":{"_uuid":"56ea3c74e421087754e114fb4dc4dbc8efc3a122","scrolled":true,"trusted":true},"cell_type":"code","source":"# X_temp.loc[X_temp['PhotoAmt'] > 10, ['PhotoAmt']] = 11\nX_temp['PhotoAmt'] = X_temp['PhotoAmt'].astype(np.int64)\n\n# Count RescuerID occurrences:\nrescuer_count = X_temp.groupby(['RescuerID'])['PetID'].count().reset_index()\nrescuer_count.columns = ['RescuerID', 'RescuerID_COUNT']\n\n# Merge as another feature onto main DF:\nX_temp = X_temp.merge(rescuer_count, how='left', on='RescuerID')\n\ncat_cols = [\n    'Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n    'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized',\n    'Health', 'Quantity', 'Fee', 'State', 'VideoAmt', 'is_mixed_breed',\n    'n_color', 'contains_chinese', 'is_nameless', 'RescuerID_COUNT',\n    'Type_state', 'Region'\n]\n\nlbe = LabelEncoder()\nfor f in cat_cols:\n    lbe = LabelEncoder()\n    X_temp[f] = lbe.fit_transform(X_temp[f])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3ae1929e9da1d3ebd55f1668bec04e13ecf4222","trusted":true},"cell_type":"code","source":"config = {}\nconfig['field_size'] = len(cat_cols)\nconfig['feature_sizes'] = list(X_temp[cat_cols].nunique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e92000e29c94e7299f2dd30778911ec7dc0dbf4","scrolled":true,"trusted":true},"cell_type":"code","source":"print('NaN structure:\\n{}'.format(np.sum(pd.isnull(X_temp))))\nprint('-'*99)\n\ncolumn_types = X_temp.dtypes\n\nprint('\\tint64 columns:\\n{}'.format(column_types[column_types == np.int64]))\nprint('\\tint32 columns:\\n{}'.format(column_types[column_types == np.int32]))\nprint('\\n\\tfloat columns:\\n{}'.format(column_types[column_types == 'float']))\nprint('\\n\\tto encode categorical columns:\\n{}'.format(column_types[column_types == 'object']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b2c1de1e6fb027e6fd0508842dd158cefb1bf6c"},"cell_type":"markdown","source":"## Numerical feature procession (normalization, percent encoding)"},{"metadata":{"trusted":true,"_uuid":"6ed24c94cb0e1b87efefa72049abde6f8ebde87a"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = MinMaxScaler()\nnum_cols = [\n    'population_density', 'Population', 'Total Area', '2016 GDP(RM Million)', '2016 GDPper capita(RM)',\n    'HDI', 'GDP Growth', 'Service', 'Manufacturing', 'Agriculture', 'Mining', \n    'Construction', 'Import'\n]\nX_temp[num_cols] = scaler.fit_transform(X_temp[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af51564353142822ad6942870cd2e5bc2d80f84d"},"cell_type":"code","source":"def percent_encoder(col_name, main_df):\n    size = main_df.shape[0]\n    temp_df = main_df.groupby([col_name])['PetID'].count() / size\n    temp_df = temp_df.reset_index()\n    temp_df.columns = [col_name, col_name + '_PERCENT']\n    return main_df.merge(temp_df, how='left', on=col_name)\n\nfor c in cat_cols:\n    X_temp = percent_encoder(c, X_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"71c2770b688c684ad4fb9a5b04505589e3f950a8"},"cell_type":"code","source":"print('NaN structure:\\n{}'.format(np.sum(pd.isnull(X_temp))))\nprint('-'*99)\n\ncolumn_types = X_temp.dtypes\n\nprint('\\tint64 columns:\\n{}'.format(column_types[column_types == np.int64]))\nprint('\\tint32 columns:\\n{}'.format(column_types[column_types == np.int32]))\nprint('\\n\\tfloat columns:\\n{}'.format(column_types[column_types == 'float']))\nprint('\\n\\tto encode categorical columns:\\n{}'.format(column_types[column_types == 'object']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c377415602ddf7b2e4910b72efe218e2c624a84"},"cell_type":"markdown","source":"# Print categorical and numerical feature names"},{"metadata":{"trusted":true,"_uuid":"f9fb7c9ec31d839e35f8db6b4b900cd19298ac86"},"cell_type":"code","source":"num_cols.extend(\n    ['Type_PERCENT', 'Age_PERCENT', 'Breed1_PERCENT', 'Breed2_PERCENT',\n     'Gender_PERCENT', 'Color1_PERCENT', 'Color2_PERCENT', 'Color3_PERCENT', \n     'MaturitySize_PERCENT', 'FurLength_PERCENT', 'Vaccinated_PERCENT', \n     'Dewormed_PERCENT', 'Sterilized_PERCENT', 'Health_PERCENT', 'Quantity_PERCENT',\n     'Fee_PERCENT', 'State_PERCENT', 'VideoAmt_PERCENT', 'is_mixed_breed_PERCENT',\n     'n_color_PERCENT', 'contains_chinese_PERCENT', 'is_nameless_PERCENT',\n     'RescuerID_COUNT_PERCENT', 'Type_state_PERCENT', 'Region_PERCENT'\n    ]\n)\n\nprint(\"Categorical features:\\n\")\nprint(cat_cols)\nprint(\"# categorical features: \", len(cat_cols))\n\nprint(\"Numerical features:\\n\")\nprint(num_cols)\nprint(\"# numerical features: \", len(num_cols))\nprint('\\nTotal matrix size: ', X_temp.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d5f732df2a41eff192c32beb4fb3b571ed30d9a"},"cell_type":"markdown","source":"# Split train/test"},{"metadata":{"_uuid":"b05faf5ba4f0a69f7c97afe62e2b59c6a6d17993","trusted":true},"cell_type":"code","source":"train_X, test_X = X_temp.iloc[:train_size, :], X_temp.iloc[train_size:, :]\ntrain_y = y_temp.iloc[:train_size]\ntrain_y = train_y.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b54fac65fac562ef87be6a5f36aef69a7a10a0fa"},"cell_type":"markdown","source":"# Model"},{"metadata":{"_uuid":"3904caa4f7fedb1fd4db2edd762b04c37932c947","trusted":true},"cell_type":"code","source":"img_feat_dim = 512\n\nfrom fastai.text.models import EmbeddingDropout\n\nclass Dense(nn.Module):\n    def __init__(self, in_channel, out_channel, dropout=0.25):\n        super(Dense, self).__init__()\n        \n        self.linear = nn.Linear(in_channel, out_channel, bias=False)\n        self.activation = nn.PReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.bn = nn.BatchNorm1d(out_channel)\n    \n    def forward(self, x):\n        out = self.linear(x)\n        out = self.activation(out)\n        out = self.dropout(out)\n        out = self.bn(out)\n        return out\n\nclass RNNModel(nn.Module):\n    def __init__(self, rnn_type, input_size, hidden_size):\n        super(RNNModel, self).__init__()\n        self.rnn = getattr(nn, rnn_type)(input_size, hidden_size, bidirectional=True, batch_first=True)\n    \n    def init_weights(self):\n        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n        for k in ih:\n            nn.init.xavier_uniform_(k)\n        for k in hh:\n            nn.init.orthogonal_(k)\n        for k in b:\n            nn.init.constant_(k, 0)\n\n    def forward(self, x):\n        return self.rnn(x)\n    \nclass Image_Model(nn.Module):\n    def __init__(self, hidden_size, out_size, kernel_sizes, dropout, width=5):\n        super(Image_Model, self).__init__()\n        \n        self.feat_dropout = nn.Dropout(dropout)\n        self.conv_list = nn.ModuleList([WideConv(img_feat_dim, hidden_size, kernel_sizes) for _ in range(width)])\n        self.dense = Dense(hidden_size*len(kernel_sizes)*width, out_size, dropout=0)\n    \n    def forward(self, x):\n        out = x.transpose(1, 2)\n        out = self.feat_dropout(out)\n\n        out_list = []\n        for conv in self.conv_list:\n            out_list.append(conv(out))\n        \n        conc = torch.squeeze(torch.cat(out_list, 1)) \n        return self.dense(conc)\n    \nclass WideConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_sizes):\n        super(WideConv, self).__init__()\n        \n        self.conv_list = nn.ModuleList([nn.Sequential(\n            nn.Conv1d(in_channels, out_channels, k, bias=False),\n            nn.BatchNorm1d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveMaxPool1d(1)\n        ) for k in kernel_sizes])\n        \n    def forward(self, emb):\n        out_list = []\n        for conv in self.conv_list:\n            out_list.append(conv(emb))\n        \n        return torch.squeeze(torch.cat(out_list, 1))\n    \nclass Img_Pred(nn.Module):\n    def __init__(self, n_class, hidden_size, out_size, embed_size, width, kernel_sizes, dropout):\n        super(Img_Pred, self).__init__()\n        \n        self.width = width\n        self.embed = nn.Embedding(n_class, embed_size, padding_idx=0)\n        \n        self.conv_list = nn.ModuleList([WideConv(embed_size, hidden_size, kernel_sizes) for _ in range(width)])\n        self.dense = Dense(hidden_size*len(kernel_sizes)*width, out_size, dropout=dropout)\n    \n    def forward(self, x):\n        emb = self.embed(x)\n        emb = emb.transpose(1, 2)\n        \n        out_list = []\n        for conv in self.conv_list:\n            out_list.append(conv(emb))\n        conc = torch.cat(out_list, 1)\n        return self.dense(conc)\n    \nclass LSTM_TextCNN(nn.Module):\n    def __init__(self, hidden_size, out_size, embedding_matrix, embed_size, dropout, initialization=True):\n        super(LSTM_TextCNN, self).__init__()\n        \n        self.embedding = nn.Embedding(n_words, embed_size, padding_idx=0)\n        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n        self.embedding.weight.requires_grad = False\n        \n        self.embedding_dropout = EmbeddingDropout(self.embedding, dropout)\n        \n        self.lstm = RNNModel(\"LSTM\", embed_size, hidden_size)\n        self.lstm.init_weights()\n        \n        self.conv1 = nn.Conv1d(hidden_size*2, hidden_size, 1, bias=False)\n        self.bn1 = nn.BatchNorm1d(hidden_size)\n        self.conv2 = nn.Conv1d(hidden_size*2, hidden_size, 2, bias=False)\n        self.bn2 = nn.BatchNorm1d(hidden_size)\n        self.conv3 = nn.Conv1d(hidden_size*2, hidden_size, 3, bias=False)\n        self.bn3 = nn.BatchNorm1d(hidden_size)\n        self.conv4 = nn.Conv1d(hidden_size*2, hidden_size, 4, bias=False)\n        self.bn4 = nn.BatchNorm1d(hidden_size)\n        self.relu = nn.ReLU(inplace=True)\n        \n        self.dense = Dense(hidden_size*4, out_size, dropout=0)\n        \n    def forward(self, x):\n        embed = self.embedding_dropout(x)\n        out, _ = self.lstm(embed)\n        \n        out = out.transpose(1, 2)\n        \n        out1 = self.bn1(self.relu(self.conv1(out)))\n        out1 = F.adaptive_max_pool1d(out1, 1)\n        \n        out2 = self.bn2(self.relu(self.conv2(out)))\n        out2 = F.adaptive_max_pool1d(out2, 1)\n        \n        out3 = self.bn3(self.relu(self.conv3(out)))\n        out3 = F.adaptive_max_pool1d(out3, 1)\n        \n        out4 = self.bn4(self.relu(self.conv4(out)))\n        out4 = F.adaptive_max_pool1d(out4, 1)\n        \n        conc = torch.squeeze(torch.cat((out1, out2, out3, out4), 1)) \n        return self.dense(conc)\n\nclass NFM(torch.nn.Module):\n    \"\"\"\n    :parameter\n    -------------\n    field_size: size of the feature fields\n    feature_sizes: a field_size-dim array, sizes of the feature dictionary\n    embedding_size: size of the feature embedding\n    is_shallow_dropout: bool, shallow part(fm or ffm part) uses dropout or not?\n    dropout_shallow: an array of the size of 1, example:[0.5], the element is for the-first order part\n    h_depth: deep network's hidden layers' depth\n    deep_layers: a h_depth-dim array, each element is the size of corresponding hidden layers. example:[32,32] h_depth = 2\n    is_deep_dropout: bool, deep part uses dropout or not?\n    dropout_deep: an array of dropout factors,example:[0.5,0.5,0.5] h_depth=2\n    deep_layers_activation: relu or sigmoid etc\n    is_batch_norm：bool,  use batch_norm or not ?\n    random_seed: random_seed=950104 someone's birthday, my lukcy number\n    use_fm: bool\n    use_ffm: bool\n    interation_type: bool, When it's true, the element-wise product of the fm or ffm embeddings will be added together, otherwise, the element-wise prodcut of embeddings will be concatenated.\n    use_cuda: bool use gpu or cpu?\n    out_size: output size\n\n    Attention: only support logsitcs regression\n    \"\"\"\n    def __init__(self,field_size, feature_sizes, embedding_size = 8, is_shallow_dropout = True, dropout_shallow = [0.25],\n                 h_depth = 2, deep_layers = [128, 128], is_deep_dropout = True, dropout_deep=[0.25, 0.25, 0.25],\n                 deep_layers_activation = 'relu', is_batch_norm = False, random_seed = SEED,\n                 use_fm = True, use_ffm = False, interation_type = True,\n                 use_cuda = True, out_size = 1\n                 ):\n        super(NFM, self).__init__()\n        self.field_size = field_size\n        self.feature_sizes = feature_sizes\n        self.out_size = out_size\n        self.embedding_size = embedding_size\n        self.is_shallow_dropout = is_shallow_dropout\n        self.dropout_shallow = dropout_shallow\n        self.h_depth = h_depth\n        self.deep_layers = deep_layers\n        self.is_deep_dropout = is_deep_dropout\n        self.dropout_deep = dropout_deep\n        self.deep_layers_activation = deep_layers_activation\n        self.is_batch_norm = is_batch_norm\n        self.random_seed = random_seed\n        self.use_fm = use_fm\n        self.use_ffm = use_ffm\n        self.interation_type = interation_type\n        self.use_cuda = use_cuda\n        self.out_size = out_size\n\n        torch.manual_seed(self.random_seed)\n\n        \"\"\"\n            check cuda\n        \"\"\"\n        if self.use_cuda and not torch.cuda.is_available():\n            self.use_cuda = False\n            print(\"Cuda is not available, automatically changed into cpu model\")\n\n        \"\"\"\n            check use fm or ffm\n        \"\"\"\n        if self.use_fm and self.use_ffm:\n            print(\"only support one type only, please make sure to choose only fm or ffm part\")\n            exit(1)\n        elif self.use_fm:\n            print(\"The model is nfm(fm+nn layers)\")\n        elif self.use_ffm:\n            print(\"The model is nffm(ffm+nn layers)\")\n        else:\n            print(\"You have to choose more than one of (fm, ffm) models to use\")\n            exit(1)\n        \"\"\"\n            bias\n        \"\"\"\n        self.bias = torch.nn.Parameter(torch.randn(1, self.out_size))\n\n        \"\"\"\n            fm part\n        \"\"\"\n        if self.use_fm:\n#             print(\"Init fm part\")\n            self.fm_first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in self.feature_sizes])\n            if self.dropout_shallow:\n                self.fm_first_order_dropout = nn.Dropout(self.dropout_shallow[0])\n            self.fm_second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size) for feature_size in self.feature_sizes])\n#             print(\"Init fm part succeed\")\n\n        \"\"\"\n            ffm part\n        \"\"\"\n        if self.use_ffm:\n#             print(\"Init ffm part\")\n            self.ffm_first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in self.feature_sizes])\n            if self.dropout_shallow:\n                self.ffm_first_order_dropout = nn.Dropout(self.dropout_shallow[0])\n            self.ffm_second_order_embeddings = nn.ModuleList([nn.ModuleList([nn.Embedding(feature_size, self.embedding_size) for i in range(self.field_size)]) for feature_size in self.feature_sizes])\n#             print(\"Init ffm part succeed\")\n\n        \"\"\"\n            deep part\n        \"\"\"\n#         print(\"Init deep part\")\n\n        if self.is_deep_dropout:\n            self.linear_0_dropout = nn.Dropout(self.dropout_deep[0])\n        if self.interation_type:\n            self.linear_1 = nn.Linear(self.embedding_size, deep_layers[0])\n        else:\n            self.linear_1 = nn.Linear(self.field_size*(self.field_size-1)//2, deep_layers[0])\n        if self.is_batch_norm:\n            self.batch_norm_1 = nn.BatchNorm1d(deep_layers[0])\n        if self.is_deep_dropout:\n            self.linear_1_dropout = nn.Dropout(self.dropout_deep[1])\n        for i, h in enumerate(self.deep_layers[1:], 1):\n            setattr(self, 'linear_' + str(i + 1), nn.Linear(self.deep_layers[i - 1], self.deep_layers[i]))\n            if self.is_batch_norm:\n                setattr(self, 'batch_norm_' + str(i + 1), nn.BatchNorm1d(deep_layers[i]))\n            if self.is_deep_dropout:\n                setattr(self, 'linear_' + str(i + 1) + '_dropout', nn.Dropout(self.dropout_deep[i + 1]))\n\n#         print(\"Init deep part succeed\")\n        \n        self.dense = Dense(deep_layers[1], out_size, dropout=0)\n\n#         print(\"Init succeed\")\n\n    def forward(self, Xi, Xv):\n        \"\"\"\n        :param Xi_train: index input tensor, batch_size * k * 1\n        :param Xv_train: value input tensor, batch_size * k * 1\n        :return: the last output\n        \"\"\"\n        \"\"\"\n            fm part\n        \"\"\"\n        if self.use_fm:\n            fm_first_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.fm_first_order_embeddings)]\n            fm_first_order = torch.cat(fm_first_order_emb_arr,1)\n            if self.is_shallow_dropout:\n                fm_first_order = self.fm_first_order_dropout(fm_first_order)\n\n            if self.interation_type:\n                # use 2xy = (x+y)^2 - x^2 - y^2 reduce calculation\n                fm_second_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.fm_second_order_embeddings)]\n                fm_sum_second_order_emb = sum(fm_second_order_emb_arr)\n                fm_sum_second_order_emb_square = fm_sum_second_order_emb*fm_sum_second_order_emb # (x+y)^2\n                fm_second_order_emb_square = [item*item for item in fm_second_order_emb_arr]\n                fm_second_order_emb_square_sum = sum(fm_second_order_emb_square) #x^2+y^2\n                fm_second_order = (fm_sum_second_order_emb_square - fm_second_order_emb_square_sum) * 0.5\n            else:\n                fm_second_order_emb_arr = [(torch.sum(emb(Xi[:, i, :]), 1).t() * Xv[:, i]).t() for i, emb in\n                                           enumerate(self.fm_second_order_embeddings)]\n                fm_wij_arr = []\n                for i in range(self.field_size):\n                    for j in range(i + 1, self.field_size):\n                        fm_wij_arr.append(fm_second_order_emb_arr[i] * fm_second_order_emb_arr[j])\n\n\n        \"\"\"\n            ffm part\n        \"\"\"\n        if self.use_ffm:\n            ffm_first_order_emb_arr = [(torch.sum(emb(Xi[:,i,:]),1).t()*Xv[:,i]).t() for i, emb in enumerate(self.ffm_first_order_embeddings)]\n            ffm_first_order = torch.cat(ffm_first_order_emb_arr,1)\n            if self.is_shallow_dropout:\n                ffm_first_order = self.ffm_first_order_dropout(ffm_first_order)\n            ffm_second_order_emb_arr = [[(torch.sum(emb(Xi[:,i,:]), 1).t() * Xv[:,i]).t() for emb in  f_embs] for i, f_embs in enumerate(self.ffm_second_order_embeddings)]\n            ffm_wij_arr = []\n            for i in range(self.field_size):\n                for j in range(i+1, self.field_size):\n                    ffm_wij_arr.append(ffm_second_order_emb_arr[i][j]*ffm_second_order_emb_arr[j][i])\n            ffm_second_order = sum(ffm_wij_arr)\n\n        \"\"\"\n            deep part\n        \"\"\"\n        if self.use_fm and self.interation_type:\n            deep_emb = fm_second_order\n        elif self.use_ffm and self.interation_type:\n            deep_emb = ffm_second_order\n        elif self.use_fm:\n            deep_emb = torch.cat([torch.sum(fm_wij,1).view([-1,1]) for fm_wij in fm_wij_arr], 1)\n        else:\n            deep_emb = torch.cat([torch.sum(ffm_wij,1).view([-1,1]) for ffm_wij in ffm_wij_arr],1)\n\n        if self.deep_layers_activation == 'sigmoid':\n            activation = F.sigmoid\n        elif self.deep_layers_activation == 'tanh':\n            activation = F.tanh\n        else:\n            activation = F.relu\n\n        if self.is_deep_dropout:\n            deep_emb = self.linear_0_dropout(deep_emb)\n        x_deep = self.linear_1(deep_emb)\n        if self.is_batch_norm:\n            x_deep = self.batch_norm_1(x_deep)\n        x_deep = activation(x_deep)\n        if self.is_deep_dropout:\n            x_deep = self.linear_1_dropout(x_deep)\n        for i in range(1, len(self.deep_layers)):\n            x_deep = getattr(self, 'linear_' + str(i + 1))(x_deep)\n            if self.is_batch_norm:\n                x_deep = getattr(self, 'batch_norm_' + str(i + 1))(x_deep)\n            x_deep = activation(x_deep)\n            if self.is_deep_dropout:\n                x_deep = getattr(self, 'linear_' + str(i + 1) + '_dropout')(x_deep)\n\n        \"\"\"\n            output\n        \"\"\"\n        \n        out = self.dense(x_deep)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b5396869e26f1fa90ba63946207be7b3503c952","trusted":true},"cell_type":"code","source":"def kappa_loss(p, y, n_classes=5, eps=1e-10):\n    \"\"\"\n    QWK loss function as described in https://arxiv.org/pdf/1612.00775.pdf\n    \n    Arguments:\n        p: a tensor with probability predictions, [batch_size, n_classes],\n        y, a tensor with one-hot encoded class labels, [batch_size, n_classes]\n    Returns:\n        QWK loss\n    \"\"\"\n    \n    W = np.zeros((n_classes, n_classes))\n    for i in range(n_classes):\n        for j in range(n_classes):\n            W[i,j] = (i-j)**2\n    \n    W = torch.from_numpy(W.astype(np.float32)).to(device)\n    \n    O = torch.matmul(y.t(), p)\n    E = torch.matmul(y.sum(dim=0).view(-1,1), p.sum(dim=0).view(1,-1)) / O.sum()\n    \n    return (W*O).sum() / ((W*E).sum() + eps)\n\ndef one_hot(batch, depth):\n    emb = nn.Embedding(depth, depth)\n    emb.weight.data = torch.eye(depth).to(device)\n    emb.weight.requires_grad = False\n    return emb(batch)\n\ndef label_smoother(batch, depth, epsilon):\n    emb = nn.Embedding(depth, depth)\n    emb.weight.data = (torch.empty(depth, depth).fill_(epsilon/(depth-1)) + torch.eye(depth) * (1-epsilon/(depth-1)*depth)).to(device)\n    emb.weight.requires_grad = False\n    return emb(batch)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eaf0339319491af7c7fd332500f2d2644c088c76","trusted":true},"cell_type":"code","source":"# Based on https://github.com/pytorch/pytorch/pull/3740\nimport math\n\nclass Nadam(Optimizer):\n    \"\"\"Implements Nadam algorithm (a variant of Adam based on Nesterov momentum).\n    It has been proposed in `Incorporating Nesterov Momentum into Adam`__.\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 2e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        schedule_decay (float, optional): momentum schedule decay (default: 4e-3)\n    __ http://cs229.stanford.edu/proj2015/054_report.pdf\n    __ http://www.cs.toronto.edu/~fritz/absps/momentum.pdf\n    \"\"\"\n\n    def __init__(self, params, lr=2e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=0, schedule_decay=4e-3):\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay, schedule_decay=schedule_decay)\n        super(Nadam, self).__init__(params, defaults)\n\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['m_schedule'] = 1.\n                    state['exp_avg'] = grad.new().resize_as_(grad).zero_()\n                    state['exp_avg_sq'] = grad.new().resize_as_(grad).zero_()\n\n                # Warming momentum schedule\n                m_schedule = state['m_schedule']\n                schedule_decay = group['schedule_decay']\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n                eps = group['eps']\n                state['step'] += 1\n                t = state['step']\n\n                if group['weight_decay'] != 0:\n                    grad = grad.add(group['weight_decay'], p.data)\n\n                momentum_cache_t = beta1 * \\\n                    (1. - 0.5 * (0.96 ** (t * schedule_decay)))\n                momentum_cache_t_1 = beta1 * \\\n                    (1. - 0.5 * (0.96 ** ((t + 1) * schedule_decay)))\n                m_schedule_new = m_schedule * momentum_cache_t\n                m_schedule_next = m_schedule * momentum_cache_t * momentum_cache_t_1\n                state['m_schedule'] = m_schedule_new\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(1. - beta1, grad)\n                exp_avg_sq.mul_(beta2).addcmul_(1. - beta2, grad, grad)\n                exp_avg_sq_prime = exp_avg_sq / (1. - beta2 ** t)\n                denom = exp_avg_sq_prime.sqrt_().add_(eps)\n\n                p.data.addcdiv_(-group['lr'] * (1. - momentum_cache_t) / (1. - m_schedule_new), grad, denom)\n                p.data.addcdiv_(-group['lr'] * momentum_cache_t_1 / (1. - m_schedule_next), exp_avg, denom)\n\n        return loss\n\nclass CosineLRWithRestarts():\n    \"\"\"Decays learning rate with cosine annealing, normalizes weight decay\n    hyperparameter value, implements restarts.\n    https://arxiv.org/abs/1711.05101\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        batch_size: minibatch size\n        epoch_size: training samples per epoch\n        restart_period: epoch count in the first restart period\n        t_mult: multiplication factor by which the next restart period will extend/shrink\n    Example:\n        >>> scheduler = CosineLRWithRestarts(optimizer, 32, 1024, restart_period=5, t_mult=1.2)\n        >>> for epoch in range(100):\n        >>>     scheduler.step()\n        >>>     train(...)\n        >>>         ...\n        >>>         optimizer.zero_grad()\n        >>>         loss.backward()\n        >>>         optimizer.step()\n        >>>         scheduler.batch_step()\n        >>>     validate(...)\n    \"\"\"\n\n    def __init__(self, optimizer, batch_size, epoch_size, restart_period=100,\n                 t_mult=2, last_epoch=-1, eta_threshold=1000, verbose=False):\n        if not isinstance(optimizer, Optimizer):\n            raise TypeError('{} is not an Optimizer'.format(\n                type(optimizer).__name__))\n        self.optimizer = optimizer\n        if last_epoch == -1:\n            for group in optimizer.param_groups:\n                group.setdefault('initial_lr', group['lr'])\n        else:\n            for i, group in enumerate(optimizer.param_groups):\n                if 'initial_lr' not in group:\n                    raise KeyError(\"param 'initial_lr' is not specified \"\n                                   \"in param_groups[{}] when resuming an\"\n                                   \" optimizer\".format(i))\n        self.base_lrs = list(map(lambda group: group['initial_lr'],\n                                 optimizer.param_groups))\n\n        self.last_epoch = last_epoch\n        self.batch_size = batch_size\n        self.epoch_size = epoch_size\n        self.eta_threshold = eta_threshold\n        self.t_mult = t_mult\n        self.verbose = verbose\n        self.base_weight_decays = list(map(lambda group: group['weight_decay'],\n                                           optimizer.param_groups))\n        self.restart_period = restart_period\n        self.restarts = 0\n        self.t_epoch = -1\n\n    def _schedule_eta(self):\n        \"\"\"\n        Threshold value could be adjusted to shrink eta_min and eta_max values.\n        \"\"\"\n        eta_min = 0\n        eta_max = 1\n        if self.restarts <= self.eta_threshold:\n            return eta_min, eta_max\n        else:\n            d = self.restarts - self.eta_threshold\n            k = d * 0.09\n            return (eta_min + k, eta_max - k)\n\n    def get_lr(self, t_cur):\n        eta_min, eta_max = self._schedule_eta()\n\n        eta_t = (eta_min + 0.5 * (eta_max - eta_min)\n                 * (1. + math.cos(math.pi *\n                                  (t_cur / self.restart_period))))\n\n        weight_decay_norm_multi = math.sqrt(self.batch_size /\n                                            (self.epoch_size *\n                                             self.restart_period))\n        lrs = [base_lr * eta_t for base_lr in self.base_lrs]\n        weight_decays = [base_weight_decay * eta_t * weight_decay_norm_multi\n                         for base_weight_decay in self.base_weight_decays]\n\n        if self.t_epoch % self.restart_period < self.t_epoch:\n            if self.verbose:\n                print(\"Restart at epoch {}\".format(self.last_epoch))\n            self.restart_period *= self.t_mult\n            self.restarts += 1\n            self.t_epoch = 0\n\n        return zip(lrs, weight_decays)\n\n    def _set_batch_size(self):\n        d, r = divmod(self.epoch_size, self.batch_size)\n        batches_in_epoch = d + 2 if r > 0 else d + 1\n        self.batch_increment = iter(torch.linspace(0, 1, batches_in_epoch))\n\n    def step(self):\n        self.last_epoch += 1\n        self.t_epoch += 1\n        self._set_batch_size()\n        self.batch_step()\n\n    def batch_step(self):\n        t_cur = self.t_epoch + next(self.batch_increment)\n        for param_group, (lr, weight_decay) in zip(self.optimizer.param_groups,\n                                                   self.get_lr(t_cur)):\n            param_group['lr'] = lr\n            param_group['weight_decay'] = weight_decay","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17a2a23b06d50e0bbbbcb4c90281467d7d10a031"},"cell_type":"markdown","source":"## Mean Target Encoding: In-Fold Operation"},{"metadata":{"trusted":true,"_uuid":"8ce6aaf582985f0b00bef0b349a4a0594a09740f"},"cell_type":"code","source":"\"\"\"\nDefine Encoding Functions\n\"\"\"\n\ndef add_noise(series, noise_level):\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\ndef target_encoder(trn_series,\n                   val_series,\n                   tst_series, \n                   target, \n                   min_samples_leaf=1, \n                   smoothing=1,\n                   noise_level=0):\n    \"\"\"\n    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n    trn_series : training categorical feature as a pd.Series\n    tst_series : test categorical feature as a pd.Series\n    target : target data as a pd.Series\n    min_samples_leaf (int) : minimum samples to take category average into account\n    smoothing (int) : smoothing effect to balance categorical average vs prior  \n    \"\"\" \n    assert len(trn_series) == len(target)\n    assert trn_series.name == val_series.name\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean \n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index \n    \n    ft_val_series = pd.merge(\n        val_series.to_frame(val_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=val_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_val_series.index = val_series.index\n    \n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    \n    # Final processing\n    return add_noise(ft_trn_series, noise_level).values, add_noise(ft_val_series, noise_level).values, add_noise(ft_tst_series, noise_level).values\n\ndef target_encoding_process(cat_cols, trn_df, val_df, tst_df, trn_y):\n    trn_mat = np.empty((len(trn_df), len(cat_cols)))\n    val_mat = np.empty((len(val_df), len(cat_cols)))\n    tst_mat = np.empty((len(tst_df), len(cat_cols)))\n    \n    for i, c in enumerate(cat_cols):\n        whole_arr = np.concatenate(target_encoder(trn_df[c], val_df[c], tst_df[c], trn_y))\n#         whole_arr = tanh_scaler(whole_arr)\n        whole_arr = (whole_arr - whole_arr.min()) / (whole_arr.max() - whole_arr.min())\n        trn_mat[:, i] = whole_arr[:len(trn_df)]\n        val_mat[:, i] = whole_arr[len(trn_df):(len(trn_df)+len(val_df))]\n        tst_mat[:, i] = whole_arr[(len(trn_df)+len(val_df)):]\n    \n    return trn_mat, val_mat, tst_mat","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4aa07708a748e7c90dd252252656b2f59d099c8e","trusted":true},"cell_type":"code","source":"# input order: Xi, Xv, Xnum, Xtext, Xname, Ximg\n\nsplits = list(StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=SEED).split(train_X, train_y))\n\nxi_test = torch.tensor(test_X[cat_cols].values, dtype=torch.long).cuda()\nxv_test = torch.ones_like(xi_test, dtype=torch.float)\nxi_test = xi_test.unsqueeze(2)\nxnum_test = torch.tensor(test_X[num_cols].values, dtype=torch.float).cuda()\nxtext_test = torch.tensor(test_word_sequences, dtype=torch.long).cuda()\nxname_test = torch.tensor(test_name_sequences, dtype=torch.long).cuda()\nximg_test = torch.tensor(img_seq_test, dtype=torch.float).cuda()\nxpred_test = torch.tensor(seresnext50_pred_test, dtype=torch.long).cuda()\nxcute_test = torch.tensor(cuteness_test, dtype=torch.long).cuda()\n\n# test_ds = torch.utils.data.TensorDataset(xi_test, xv_test, xnum_test, xtext_test, xname_test, ximg_test)\n# test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"362bbe4aa773e9c3f3fa0733babb1fa0aa37be21"},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation Functions\n\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_num_feats = len(num_cols) + len(cat_cols)\n\nclass PetFinderModel(nn.Module):\n    def __init__(self, config, cat_size, num_size, text_size, name_size, img_feat_size, img_pred_size, cute_size, in_plane, n_class, dropout=0.25):\n        super(PetFinderModel, self).__init__()\n        \n        self.cat_model = NFM(config['field_size'], \n                             config['feature_sizes'], \n                             embedding_size=8,\n                             is_shallow_dropout=False,\n                             deep_layers=[128, 128],\n                             use_cuda=True,\n                             deep_layers_activation = 'relu',\n                             dropout_deep = [0, dropout, dropout],\n                             is_batch_norm = True,\n                             use_fm=False, \n                             use_ffm=True, \n                             interation_type=False,\n                             out_size=cat_size)\n        self.num_model = Dense(n_num_feats, num_size, dropout=0)\n        self.text_model = LSTM_TextCNN(256, text_size, embedding_matrix, embed_size, dropout)\n        self.name_model = LSTM_TextCNN(128, name_size, name_embed_mat, embed_size_name, dropout=0)\n        self.img_model = Image_Model(256, img_feat_size, [1, 2, 3], dropout=0, width=5) # hidden_size, out_size, kernel_sizes, dropout, width=5\n        self.pred_model = Img_Pred(1001, 64, img_pred_size, 8, 5, [1, 2, 3], dropout=0) # n_class, hidden_size, out_size, embed_size, width, kernel_sizes, dropout\n        self.cute_model = Img_Pred(3, 64, cute_size, 8, 5, [1, 2, 3], dropout=0)\n        \n        self.dense1 = Dense(cat_size + num_size + text_size + name_size + img_feat_size + img_pred_size + cute_size, in_plane, dropout=0)\n        self.dense2 = Dense(in_plane, in_plane*2, dropout=0)\n        self.logit = nn.Linear(in_plane*2, n_class)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, Xi, Xv, Xnum, Xtext, Xname, Ximg, Xpred, Xcute):\n        cat_out = self.cat_model(Xi, Xv)\n        num_out = self.num_model(Xnum)\n        text_out = self.text_model(Xtext)\n        name_out = self.name_model(Xname)\n        img_out = self.img_model(Ximg)\n        pred_out = self.pred_model(Xpred)\n        cute_out = self.cute_model(Xcute)\n        out = torch.cat((cat_out, num_out, text_out, name_out, img_out, pred_out, cute_out), 1)\n        out = self.dense1(out)\n        out = self.dense2(out)\n        out = self.logit(out)\n        return self.softmax(out)\n    \n    def unfreeze(self):\n        self.text_model.embedding.weight.requires_grad = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22ded77229e7030d95bac5f89f4c839de35d03f2","scrolled":true,"trusted":true},"cell_type":"code","source":"TRAIN_EPOCHS = 8\nLOG_INTERVAL = 6\nweight_decay = 0.025\n\ntrain_preds1 = np.zeros((len(train_X), 5))\ntest_preds1 = np.zeros((len(test_X), 5))\n\nfor i, (train_idx, valid_idx) in enumerate(splits):\n    xi_train_fold = torch.tensor(train_X[cat_cols].values[train_idx], dtype=torch.long).cuda()\n    xv_train_fold = torch.ones_like(xi_train_fold, dtype=torch.float)\n    xi_train_fold = xi_train_fold.unsqueeze(2)\n#     xnum_train_fold = torch.tensor(train_X[num_cols].values[train_idx], dtype=torch.float).cuda()\n    xtext_train_fold = torch.tensor(train_word_sequences[train_idx], dtype=torch.long).cuda()\n    xname_train_fold = torch.tensor(train_name_sequences[train_idx], dtype=torch.long).cuda()\n    ximg_train_fold = torch.tensor(img_seq_train[train_idx], dtype=torch.float).cuda()\n    xpred_train_fold = torch.tensor(seresnext50_pred_train[train_idx], dtype=torch.long).cuda()\n    xcute_train_fold = torch.tensor(cuteness_train[train_idx], dtype=torch.long).cuda()\n    y_train_fold  = torch.tensor(train_y.values[train_idx], dtype=torch.long).cuda()\n    \n    xi_valid_fold = torch.tensor(train_X[cat_cols].values[valid_idx], dtype=torch.long).cuda()\n    xv_valid_fold = torch.ones_like(xi_valid_fold, dtype=torch.float)\n    xi_valid_fold = xi_valid_fold.unsqueeze(2)\n#     xnum_valid_fold = torch.tensor(train_X[num_cols].values[valid_idx], dtype=torch.float).cuda()\n    xtext_valid_fold = torch.tensor(train_word_sequences[valid_idx], dtype=torch.long).cuda()\n    xname_valid_fold = torch.tensor(train_name_sequences[valid_idx], dtype=torch.long).cuda()\n    ximg_valid_fold = torch.tensor(img_seq_train[valid_idx], dtype=torch.float).cuda()\n    xpred_valid_fold = torch.tensor(seresnext50_pred_train[valid_idx], dtype=torch.long).cuda()\n    xcute_valid_fold = torch.tensor(cuteness_train[valid_idx], dtype=torch.long).cuda()\n    y_valid_fold  = torch.tensor(train_y.values[valid_idx], dtype=torch.long).cuda()\n    \n     # get target encoded features\n    xtge_train_fold, xtge_valid_fold, xtge_test_fold = target_encoding_process(cat_cols, train_X.iloc[train_idx], train_X.iloc[valid_idx], test_X, train_y.iloc[train_idx])\n    xnum_train_fold = torch.tensor(np.concatenate((train_X[num_cols].values[train_idx], xtge_train_fold), axis=1), dtype=torch.float).cuda()\n    xnum_valid_fold = torch.tensor(np.concatenate((train_X[num_cols].values[valid_idx], xtge_valid_fold), axis=1), dtype=torch.float).cuda()\n    xnum_test = torch.tensor(np.concatenate((test_X[num_cols].values, xtge_test_fold), axis=1), dtype=torch.float).cuda()\n    \n    test_ds = torch.utils.data.TensorDataset(xi_test, xv_test, xnum_test, xtext_test, xname_test, ximg_test, xpred_test, xcute_test)\n    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n    \n    # cat_size, num_size, text_size, name_size, img_feat_size, img_pred_size, cute_size, in_plane, n_class\n    model = PetFinderModel(config, 128, 128, 128, 128, 128, 128, 128, 64, 5, dropout=0.25).cuda()\n    \n    criterion = kappa_loss\n    optimizer = Nadam(model.parameters(), lr=0.01)\n    scheduler = CosineLRWithRestarts(optimizer, BATCH_SIZE, len(xi_train_fold), restart_period=TRAIN_EPOCHS, t_mult=1, verbose=True)\n    \n    # input order: Xi, Xv, Xnum, Xtext, Xname, Ximg\n    train_ds = torch.utils.data.TensorDataset(\n        xi_train_fold, xv_train_fold, xnum_train_fold, xtext_train_fold, \n        xname_train_fold, ximg_train_fold, xpred_train_fold, xcute_train_fold, y_train_fold)\n    valid_ds = torch.utils.data.TensorDataset(\n        xi_valid_fold, xv_valid_fold, xnum_valid_fold, xtext_valid_fold, \n        xname_valid_fold, ximg_valid_fold, xpred_valid_fold, xcute_valid_fold, y_valid_fold)\n    \n    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n    \n    print(f'Fold {i + 1}')\n    \n    for epoch in range(TRAIN_EPOCHS):\n        start_time = time.time()\n        start_time2 = time.time()\n        \n        scheduler.step()\n        model.train()\n        total_loss = 0.\n        avg_loss = 0.\n        \n        if epoch == 1:\n            model.unfreeze()\n        \n        for batch_idx, (xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch, y_batch) in enumerate(train_loader):\n            y_pred = model(xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch)\n            loss = criterion(y_pred, one_hot(y_batch, 5))\n            optimizer.zero_grad()\n            loss.backward()\n#             for group in optimizer.param_groups:\n#                 for param in group['params']:\n#                     param.data = param.data.add(-weight_decay * group['lr'], param.data)\n            optimizer.step()\n            scheduler.batch_step()\n        \n            avg_loss += loss.item() / len(train_loader)\n            total_loss += loss.item()\n            \n            if batch_idx % LOG_INTERVAL == 0 and batch_idx > 0:\n                cur_loss = total_loss / LOG_INTERVAL\n                elapsed_time2 = time.time() - start_time2\n                print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n                    'loss {:5.4f}'.format(\n                        epoch+1, batch_idx, len(train_loader),\n                        elapsed_time2 * 1000 / LOG_INTERVAL, cur_loss))\n                total_loss = 0\n                start_time2 = time.time()\n        \n        model.eval()\n        valid_preds_fold = np.zeros((xi_valid_fold.size(0), 5))\n        avg_val_loss = 0.\n        \n        for i, (xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch, y_batch) in enumerate(valid_loader):\n            y_pred = model(xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch).detach()\n            avg_val_loss += criterion(y_pred, one_hot(y_batch, 5)).item() / len(valid_loader)\n            valid_preds_fold[i * BATCH_SIZE:(i+1) * BATCH_SIZE] = y_pred.cpu().numpy()\n        \n        elapsed_time = time.time() - start_time \n        print('Epoch {}/{} | train_loss={:.4f} | val_loss={:.4f} | time={:.2f}s'.format(\n            epoch + 1, TRAIN_EPOCHS, avg_loss, avg_val_loss, elapsed_time))\n            \n    test_preds_fold = np.zeros((len(test_X), 5))\n    for i, (xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch) in enumerate(test_loader):\n        y_pred = model(xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch).detach()\n        test_preds_fold[i * BATCH_SIZE:(i+1) * BATCH_SIZE] = y_pred.cpu().numpy()\n        \n    train_preds1[valid_idx] = valid_preds_fold\n    test_preds1 += test_preds_fold / n_fold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0983c0c0307751f22af5f1d44abad2592a6536b"},"cell_type":"markdown","source":"> ### Model 1 Evaluation"},{"metadata":{"_uuid":"65d87a709643f7e12f84a369aa1856129c32315f","trusted":true},"cell_type":"code","source":"print(\"CV: \", quadratic_weighted_kappa(train_y.values, np.argmax(train_preds1, 1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_num_feats = len(num_cols)\n\nclass PetFinderModel2(nn.Module):\n    def __init__(self, config, cat_size, num_size, text_size, name_size, img_feat_size, img_pred_size, cute_size, in_plane, n_class, dropout=0.25):\n        super(PetFinderModel2, self).__init__()\n        \n        self.cat_model = NFM(config['field_size'], \n                             config['feature_sizes'], \n                             embedding_size=8,\n                             is_shallow_dropout=False,\n                             deep_layers=[128, 128],\n                             use_cuda=True,\n                             deep_layers_activation = 'relu',\n                             dropout_deep = [0, dropout, dropout],\n                             is_batch_norm = True,\n                             use_fm=False, \n                             use_ffm=True, \n                             interation_type=True,\n                             out_size=cat_size)\n        self.num_model = Dense(n_num_feats, num_size, dropout=0)\n        self.text_model = LSTM_TextCNN(256, text_size, embedding_matrix, embed_size, dropout)\n        self.name_model = LSTM_TextCNN(128, name_size, name_embed_mat, embed_size_name, dropout=0)\n        self.img_model = Image_Model(256, img_feat_size, [1, 2, 3], dropout=0, width=5) # hidden_size, out_size, kernel_sizes, dropout, width=5\n        self.pred_model = Img_Pred(1001, 64, img_pred_size, 8, 5, [1, 2, 3], dropout=0) # n_class, hidden_size, out_size, embed_size, width, kernel_sizes, dropout\n        self.cute_model = Img_Pred(3, 64, cute_size, 8, 5, [1, 2, 3], dropout=0) # n_class, hidden_size, out_size, embed_size, width, kernel_sizes, dropout\n        \n        self.dense1 = Dense(cat_size + num_size + text_size + name_size + img_feat_size + img_pred_size + cute_size, in_plane, dropout=0)\n        self.dense2 = Dense(in_plane, in_plane*2, dropout=0)\n        self.logit = nn.Linear(in_plane*2, n_class)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, Xi, Xv, Xnum, Xtext, Xname, Ximg, Xpred, Xcute):\n        cat_out = self.cat_model(Xi, Xv)\n        num_out = self.num_model(Xnum)\n        text_out = self.text_model(Xtext)\n        name_out = self.name_model(Xname)\n        img_out = self.img_model(Ximg)\n        pred_out = self.pred_model(Xpred)\n        cute_out = self.cute_model(Xcute)\n        out = torch.cat((cat_out, num_out, text_out, name_out, img_out, pred_out, cute_out), 1)\n        out = self.dense1(out)\n        out = self.dense2(out)\n        out = self.logit(out)\n        return self.softmax(out)\n    \n    def unfreeze(self):\n        self.text_model.embedding.weight.requires_grad = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_EPOCHS = 8\nLOG_INTERVAL = 6\nweight_decay = 0.025\n\ntrain_preds2 = np.zeros((len(train_X), 5))\ntest_preds2 = np.zeros((len(test_X), 5))\n\nfor i, (train_idx, valid_idx) in enumerate(splits):\n    xi_train_fold = torch.tensor(train_X[cat_cols].values[train_idx], dtype=torch.long).cuda()\n    xv_train_fold = torch.ones_like(xi_train_fold, dtype=torch.float)\n    xi_train_fold = xi_train_fold.unsqueeze(2)\n    xnum_train_fold = torch.tensor(train_X[num_cols].values[train_idx], dtype=torch.float).cuda()\n    xtext_train_fold = torch.tensor(train_word_sequences[train_idx], dtype=torch.long).cuda()\n    xname_train_fold = torch.tensor(train_name_sequences[train_idx], dtype=torch.long).cuda()\n    ximg_train_fold = torch.tensor(img_seq_train[train_idx], dtype=torch.float).cuda()\n    xpred_train_fold = torch.tensor(seresnext50_pred_train[train_idx], dtype=torch.long).cuda()\n    xcute_train_fold = torch.tensor(cuteness_train[train_idx], dtype=torch.long).cuda()\n    y_train_fold  = torch.tensor(train_y.values[train_idx], dtype=torch.long).cuda()\n    \n    xi_valid_fold = torch.tensor(train_X[cat_cols].values[valid_idx], dtype=torch.long).cuda()\n    xv_valid_fold = torch.ones_like(xi_valid_fold, dtype=torch.float)\n    xi_valid_fold = xi_valid_fold.unsqueeze(2)\n    xnum_valid_fold = torch.tensor(train_X[num_cols].values[valid_idx], dtype=torch.float).cuda()\n    xtext_valid_fold = torch.tensor(train_word_sequences[valid_idx], dtype=torch.long).cuda()\n    xname_valid_fold = torch.tensor(train_name_sequences[valid_idx], dtype=torch.long).cuda()\n    ximg_valid_fold = torch.tensor(img_seq_train[valid_idx], dtype=torch.float).cuda()\n    xpred_valid_fold = torch.tensor(seresnext50_pred_train[valid_idx], dtype=torch.long).cuda()\n    xcute_valid_fold = torch.tensor(cuteness_train[valid_idx], dtype=torch.long).cuda()\n    y_valid_fold  = torch.tensor(train_y.values[valid_idx], dtype=torch.long).cuda()\n    \n     # get target encoded features\n#     xtge_train_fold, xtge_valid_fold, xtge_test_fold = target_encoding_process(cat_cols, train_X.iloc[train_idx], train_X.iloc[valid_idx], test_X, train_y.iloc[train_idx])\n#     xnum_train_fold = torch.tensor(np.concatenate((train_X[num_cols].values[train_idx], xtge_train_fold), axis=1), dtype=torch.float).cuda()\n#     xnum_valid_fold = torch.tensor(np.concatenate((train_X[num_cols].values[valid_idx], xtge_valid_fold), axis=1), dtype=torch.float).cuda()\n#     xnum_test = torch.tensor(np.concatenate((test_X[num_cols].values, xtge_test_fold), axis=1), dtype=torch.float).cuda()\n    \n    xnum_test = torch.tensor(test_X[num_cols].values, dtype=torch.float).cuda()\n    test_ds = torch.utils.data.TensorDataset(xi_test, xv_test, xnum_test, xtext_test, xname_test, ximg_test, xpred_test, xcute_test)\n    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n    \n    # cat_size, num_size, text_size, name_size, img_feat_size, img_pred_size, cute_size, in_plane, n_class\n    model = PetFinderModel(config, 128, 128, 128, 128, 128, 128, 128, 64, 5, dropout=0.25).cuda()\n    \n    criterion = kappa_loss\n    optimizer = Nadam(model.parameters(), lr=0.01)\n    scheduler = CosineLRWithRestarts(optimizer, BATCH_SIZE, len(xi_train_fold), restart_period=TRAIN_EPOCHS, t_mult=1, verbose=True)\n    \n    # input order: Xi, Xv, Xnum, Xtext, Xname, Ximg\n    train_ds = torch.utils.data.TensorDataset(\n        xi_train_fold, xv_train_fold, xnum_train_fold, xtext_train_fold, \n        xname_train_fold, ximg_train_fold, xpred_train_fold, xcute_train_fold, y_train_fold)\n    valid_ds = torch.utils.data.TensorDataset(\n        xi_valid_fold, xv_valid_fold, xnum_valid_fold, xtext_valid_fold, \n        xname_valid_fold, ximg_valid_fold, xpred_valid_fold, xcute_valid_fold, y_valid_fold)\n    \n    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n    \n    print(f'Fold {i + 1}')\n    \n    for epoch in range(TRAIN_EPOCHS):\n        start_time = time.time()\n        start_time2 = time.time()\n        \n        scheduler.step()\n        model.train()\n        total_loss = 0.\n        avg_loss = 0.\n        \n        if epoch == 1:\n            model.unfreeze()\n        \n        for batch_idx, (xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch, y_batch) in enumerate(train_loader):\n            y_pred = model(xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch)\n            loss = criterion(y_pred, one_hot(y_batch, 5))\n            optimizer.zero_grad()\n            loss.backward()\n#             for group in optimizer.param_groups:\n#                 for param in group['params']:\n#                     param.data = param.data.add(-weight_decay * group['lr'], param.data)\n            optimizer.step()\n            scheduler.batch_step()\n        \n            avg_loss += loss.item() / len(train_loader)\n            total_loss += loss.item()\n            \n            if batch_idx % LOG_INTERVAL == 0 and batch_idx > 0:\n                cur_loss = total_loss / LOG_INTERVAL\n                elapsed_time2 = time.time() - start_time2\n                print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '\n                    'loss {:5.4f}'.format(\n                        epoch+1, batch_idx, len(train_loader),\n                        elapsed_time2 * 1000 / LOG_INTERVAL, cur_loss))\n                total_loss = 0\n                start_time2 = time.time()\n        \n        model.eval()\n        valid_preds_fold = np.zeros((xi_valid_fold.size(0), 5))\n        avg_val_loss = 0.\n        \n        for i, (xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch, y_batch) in enumerate(valid_loader):\n            y_pred = model(xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch).detach()\n            avg_val_loss += criterion(y_pred, one_hot(y_batch, 5)).item() / len(valid_loader)\n            valid_preds_fold[i * BATCH_SIZE:(i+1) * BATCH_SIZE] = y_pred.cpu().numpy()\n        \n        elapsed_time = time.time() - start_time \n        print('Epoch {}/{} | train_loss={:.4f} | val_loss={:.4f} | time={:.2f}s'.format(\n            epoch + 1, TRAIN_EPOCHS, avg_loss, avg_val_loss, elapsed_time))\n            \n    test_preds_fold = np.zeros((len(test_X), 5))\n    for i, (xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch) in enumerate(test_loader):\n        y_pred = model(xi_batch, xv_batch, xnum_batch, xtext_batch, xname_batch, ximg_batch, xpred_batch, xcute_batch).detach()\n        test_preds_fold[i * BATCH_SIZE:(i+1) * BATCH_SIZE] = y_pred.cpu().numpy()\n        \n    train_preds2[valid_idx] = valid_preds_fold\n    test_preds2 += test_preds_fold / n_fold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model2: Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CV: \", quadratic_weighted_kappa(train_y.values, np.argmax(train_preds2, 1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# OOF CV\nprint(\"CV: \", quadratic_weighted_kappa(train_y.values, np.argmax((train_preds1+train_preds2)/2, 1)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6ba108c661dfe0011903c924928da654638b890","trusted":false},"cell_type":"code","source":"# Generate submission:\n\nsample_submission[\"AdoptionSpeed\"] = np.argmax((test_preds1+test_preds2)/2, 1).astype(np.int32)\nsample_submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}